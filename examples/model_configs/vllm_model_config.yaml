model:
  base_params:
    model_args: "pretrained=NousResearch/DeepHermes-3-Llama-3-8B-Preview,revision=main,dtype=bfloat16,max_model_length=32000" # pretrained=model_name,trust_remote_code=boolean,revision=revision_to_use,model_parallel=True ...
  generation:
    temperature: 0.3
    max_new_tokens: 12000
